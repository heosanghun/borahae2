# 런웨이 결과 영상 일관성 문제 — 원인 분석

## 현상
- **런웨이 결과 이미지**(위): 사용자가 선택한 장소·얼굴로 합성된 **한 장의 이미지**
- **런웨이 결과 영상**(아래): 위 이미지와 **인물, 스타일, 배경 효과가 다른** 영상이 생성됨

→ “결과 이미지를 입력해서 영상을 만든다”고 기대하지만, 실제로는 **전혀 다른 영상**이 나옴.

---

## 근본 원인

### 1. 사용 중인 API는 **이미지를 입력으로 받지 않음**

현재 영상 생성에 쓰는 API는 아래와 같습니다.

- **엔드포인트**: `generativelanguage.googleapis.com/v1beta/models/veo-3.1-generate-preview:predictLongRunning`
- **요청 본문**: `instances: [{ prompt: prompt }]` — **텍스트(프롬프트)만** 전달

코드 주석에도 다음과 같이 적혀 있습니다.

- `startVeoVideoGenerationFromImage` 주석:  
  **"REST predictLongRunning는 image/fileUri/imageBytes 미지원하므로 텍스트 프롬프트만 전송."**

즉,  
**“런웨이 결과 이미지를 API에 넣어서 그 이미지로 영상을 만든다”가 아니라,**  
**“이미지를 보지 않고, 텍스트만 보고 영상을 새로 만든다”** 구조입니다.

---

### 2. 실제 데이터 흐름 (현재 구현)

```
[런웨이 결과 이미지]
       ↓
  Gemini 이미지 분석 (callGeminiImageToText)
  → "이 이미지를 영어 문장으로 설명"
       ↓
  [영문 텍스트 설명]  ← 여기서 이미지는 더 이상 사용되지 않음
       ↓
  Veo API (startVeoVideoGeneration)
  → "이 텍스트만" 받아서 영상 생성
       ↓
  [새로 생성된 영상]  ← 이미지와 무관하게, 텍스트만으로 생성
```

- Veo는 **런웨이 결과 이미지를 한 번도 보지 않습니다.**
- 입력은 **항상 “이미지를 설명한 텍스트” 하나**뿐입니다.

그래서 “결과 이미지를 입력해서 영상을 만든다”가 아니라,  
“결과 이미지를 **글**로 바꾼 뒤, 그 **글**만으로 영상을 만든다”에 가깝습니다.

---

### 3. 왜 인물·스타일·배경이 달라지는가

1. **텍스트 한계**
   - 얼굴 생김새, 피부톤, 헤어스타일, 의상 디테일, **실사 vs 애니메이션** 같은 스타일을 문장으로 완전히 옮기기 어렵습니다.
   - Gemini가 아무리 잘 설명해도, “그 한 장의 이미지와 픽셀 단위로 같은 장면”을 텍스트만으로 전달하는 것은 불가능에 가깝습니다.

2. **Veo의 해석**
   - Veo는 **받은 텍스트만** 보고, 그에 맞는 장면을 **자유롭게 해석해 새로 그립니다.**
   - “같은 사람, 같은 옷, 같은 배경”을 유지하라는 제약이 API 수준에 없기 때문에,  
     인물이 다른 사람처럼 바뀌고, 스타일(실사/애니메이션)이나 배경 효과(불꽃 위치·색 등)가 달라질 수 있습니다.

3. **정리**
   - **입력**: Veo 입장에서는 “텍스트 하나”만 입력.
   - **출력**: 그 텍스트에 “맡겨진” 새 영상 → 이미지와의 **일관성은 보장되지 않음**.

---

## 원인 요약

| 구분 | 내용 |
|------|------|
| **근본 원인** | 사용 중인 Veo API(`predictLongRunning`)가 **이미지 입력(Image-to-Video)** 을 지원하지 않고, **텍스트 프롬프트만** 받음. |
| **구조적 원인** | “이미지 → (설명용) 텍스트 → 그 텍스트로 영상 생성” 구조라, **영상은 이미지가 아니라 텍스트에만 기반**함. |
| **결과** | 인물, 스타일, 배경이 달라져도 “다른 영상”이 나오는 것이 현재 API/구조에서는 자연스러운 결과임. |

---

## 개선 방향 (참고)

- **이미지를 직접 입력하는 영상 API 사용**
  - 예: Vertex AI의 Veo **Image-to-Video** (이미지 + 프롬프트로 영상 생성) 등.
  - 단, 현재 프로젝트는 **Gemini API 키**(`generativelanguage.googleapis.com`)를 쓰고 있어, Vertex AI와는 인증·엔드포인트가 다름.  
    이미지 입력 영상 생성이 필요하면 Vertex AI 설정·연동 검토가 필요함.
- **현재 API만 쓸 때**
  - “결과 이미지를 **입력**해서 만든 영상”이 아니라,  
    “결과 이미지를 **참고해서 만든 글**로 생성한 영상”이라고 UI/문구로 안내하는 방식으로 기대치를 맞추는 것이 현실적임.

이 문서는 위와 같은 이유로 **런웨이 결과 영상이 결과 이미지와 일관되지 않는 현상**의 원인을 기술한 것입니다.
